{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "\n",
    "### Train set data\n",
    "X_train_features = train_features.drop(columns=[\"pid\"])\n",
    "X_train_pid = train_features.get(\"pid\") ## just in case if needed\n",
    "y_train_labels = train_labels.drop(columns = [\"pid\"])\n",
    "train_label_pid = train_labels.get(\"pid\") ## just in case if needed\n",
    "\n",
    "### Test set data\n",
    "X_test_features = test_features.drop(columns = [\"pid\"])\n",
    "X_test_pid = test_features.get(\"pid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pids(feat_dataframe):\n",
    "    \n",
    "    \n",
    "    all_pids = feat_dataframe[\"pid\"].unique()\n",
    "    return all_pids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pid = extract_pids(train_features)\n",
    "\n",
    "train_pid, val_pid = train_test_split(all_pid, train_size= 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(missing_values=np.NaN,n_nearest_features=4)\n",
    "mask = train_features['pid'].isin(train_pid)\n",
    "oo = train_features.loc[mask]#.drop(columns = [\"pid\"])\n",
    "idf=pd.DataFrame(imputer.fit_transform(oo))\n",
    "idf.columns=oo.columns\n",
    "idf.index=oo.index\n",
    "\n",
    "\n",
    "mask2 = train_labels['pid'].isin(val_pid)\n",
    "val_labels = train_labels.loc[mask2].drop(columns = [\"pid\"]).to_numpy()\n",
    "val_features = train_features['pid'].isin(val_pid).drop(columns = [\"pid\"])\n",
    "\n",
    "mask3 = train_features['pid'].isin(val_pid)\n",
    "pp = train_features.loc[mask3]#.drop(columns = [\"pid\"])\n",
    "idf_val=pd.DataFrame(imputer.fit_transform(pp))\n",
    "idf_val.columns=pp.columns\n",
    "idf_val.index=pp.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pid  Time   Age  EtCO2  PTT   BUN  Lactate  Temp  Hgb  HCO3  ...  \\\n",
      "0          1     3  34.0    NaN  NaN  12.0      NaN  36.0  8.7  24.0  ...   \n",
      "1          1     4  34.0    NaN  NaN   NaN      NaN  36.0  NaN   NaN  ...   \n",
      "2          1     5  34.0    NaN  NaN   NaN      NaN  36.0  NaN   NaN  ...   \n",
      "3          1     6  34.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "4          1     7  34.0    NaN  NaN   NaN      NaN   NaN  NaN   NaN  ...   \n",
      "...      ...   ...   ...    ...  ...   ...      ...   ...  ...   ...  ...   \n",
      "227923  9998     8  89.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "227924  9998     9  89.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "227925  9998    10  89.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "227926  9998    11  89.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "227927  9998    12  89.0    NaN  NaN   NaN      NaN  37.0  NaN   NaN  ...   \n",
      "\n",
      "        Alkalinephos   SpO2  Bilirubin_direct  Chloride   Hct  Heartrate  \\\n",
      "0                NaN  100.0               NaN     114.0  24.6       94.0   \n",
      "1                NaN  100.0               NaN       NaN   NaN       99.0   \n",
      "2                NaN  100.0               NaN       NaN   NaN       92.0   \n",
      "3                NaN  100.0               NaN       NaN   NaN       88.0   \n",
      "4                NaN  100.0               NaN       NaN  22.4       81.0   \n",
      "...              ...    ...               ...       ...   ...        ...   \n",
      "227923           NaN  100.0               NaN       NaN   NaN       95.0   \n",
      "227924           NaN  100.0               NaN       NaN   NaN       94.0   \n",
      "227925           NaN  100.0               NaN       NaN   NaN      101.0   \n",
      "227926           NaN  100.0               NaN       NaN   NaN       96.0   \n",
      "227927           NaN  100.0               NaN       NaN   NaN      100.0   \n",
      "\n",
      "        Bilirubin_total  TroponinI   ABPs    pH  \n",
      "0                   NaN        NaN  142.0  7.33  \n",
      "1                   NaN        NaN  125.0  7.33  \n",
      "2                   NaN        NaN  110.0  7.37  \n",
      "3                   NaN        NaN  104.0  7.37  \n",
      "4                   NaN        NaN  100.0  7.41  \n",
      "...                 ...        ...    ...   ...  \n",
      "227923              NaN        NaN  123.0   NaN  \n",
      "227924              NaN        NaN  142.0   NaN  \n",
      "227925              NaN        NaN  143.0   NaN  \n",
      "227926              NaN       0.85  126.0   NaN  \n",
      "227927              NaN        NaN  156.0   NaN  \n",
      "\n",
      "[182352 rows x 37 columns] pid                 0\n",
      "Time                0\n",
      "Age                 0\n",
      "EtCO2               0\n",
      "PTT                 0\n",
      "BUN                 0\n",
      "Lactate             0\n",
      "Temp                0\n",
      "Hgb                 0\n",
      "HCO3                0\n",
      "BaseExcess          0\n",
      "RRate               0\n",
      "Fibrinogen          0\n",
      "Phosphate           0\n",
      "WBC                 0\n",
      "Creatinine          0\n",
      "PaCO2               0\n",
      "AST                 0\n",
      "FiO2                0\n",
      "Platelets           0\n",
      "SaO2                0\n",
      "Glucose             0\n",
      "ABPm                0\n",
      "Magnesium           0\n",
      "Potassium           0\n",
      "ABPd                0\n",
      "Calcium             0\n",
      "Alkalinephos        0\n",
      "SpO2                0\n",
      "Bilirubin_direct    0\n",
      "Chloride            0\n",
      "Hct                 0\n",
      "Heartrate           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "ABPs                0\n",
      "pH                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(oo,idf_val.isna().sum(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(dataframe):\n",
    "    for (columnName, columnData) in dataframe.iteritems():\n",
    "        numb_rows = columnData.shape\n",
    "        not_NaN = columnData.count()\n",
    "        if not_NaN==0: continue\n",
    "        elif not_NaN == 1:\n",
    "            dataframe[columnName] = columnData.fillna(columnData.mean())\n",
    "        else:\n",
    "            dataframe[columnName] = columnData.interpolate()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(patient_data):\n",
    "    relevant_data = patient_data\n",
    "    #relevant_data = patient_data.drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    feat1 = relevant_data.mean().to_numpy().reshape(1,-1)\n",
    "    feat2 = relevant_data.std().to_numpy().reshape(1,-1)\n",
    "    feat3 = relevant_data.max().to_numpy().reshape(1,-1)\n",
    "    patient_features = np.hstack((feat1,feat2))\n",
    "    return patient_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features(idf[idf['pid'] == train_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))\n",
    "labels = train_labels[train_labels['pid'] == train_pid[0]].drop(columns=[\"pid\"]).to_numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15196, 68) (1, 15) (15196, 15)\n"
     ]
    }
   ],
   "source": [
    "for pid in train_pid[1:]:\n",
    "    X_pid = idf[idf['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    features = np.vstack((features,X_feat))\n",
    "    y_pid = train_labels[train_labels['pid'] == pid].drop(columns=[\"pid\"])\n",
    "    labels= np.vstack((labels,y_pid))\n",
    "    \n",
    "print(features.shape, y_pid.shape, labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = create_features(idf_val[idf_val['pid'] == val_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))\n",
    "val_labels = train_labels[train_labels['pid'] == val_pid[0]].drop(columns=[\"pid\"]).to_numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3799, 68) (1, 15) (3799, 15)\n"
     ]
    }
   ],
   "source": [
    "for pid in val_pid[1:]:\n",
    "    X_pid = idf_val[idf_val['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    val_features = np.vstack((val_features,X_feat))\n",
    "    y_pid = train_labels[train_labels['pid'] == pid].drop(columns=[\"pid\"])\n",
    "    val_labels= np.vstack((val_labels,y_pid))\n",
    "    \n",
    "print(val_features.shape, y_pid.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels[0,1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='sigmoid', probability= True)\n",
    "clf.fit(features, labels[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict_proba(val_features[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "test_pid = extract_pids(test_features)\n",
    "mask_test = test_features['pid'].isin(test_pid)\n",
    "ii = test_features.loc[mask_test]#.drop(columns = [\"pid\"])\n",
    "idf_test=pd.DataFrame(imputer.fit_transform(ii))\n",
    "idf_test.columns=ii.columns\n",
    "idf_test.index=ii.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_features = create_features(idf_test[idf_test['pid'] == test_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 68)\n"
     ]
    }
   ],
   "source": [
    "for pid in test_pid[1:]:\n",
    "    X_pid = idf_test[idf_test['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    t_features = np.vstack((t_features,X_feat))\n",
    "\n",
    "    \n",
    "print(t_features.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict_proba(t_features[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664,)\n",
      "(12664, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ss =  test_pid\n",
    "print(y_hat[:,0].shape)\n",
    "ss = np.column_stack((ss,y_hat[:,0]))\n",
    "print(ss[1:10,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 11)\n"
     ]
    }
   ],
   "source": [
    "test_labels = test_pid\n",
    "for i in range(0,10):\n",
    "    clf = svm.SVC(kernel='sigmoid', probability= True)\n",
    "    clf.fit(features, labels[:,i])\n",
    "    y_hat = clf.predict_proba(t_features[:,:])\n",
    "    test_labels = np.column_stack((test_labels,y_hat[:,0]))\n",
    "    \n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0. 10001. 10003. 10004. 10005. 10008. 10011. 10017. 10018. 10019.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0:10,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='sigmoid', probability= False)\n",
    "clf.fit(features, labels[:,10])\n",
    "y_hat = clf.predict(t_features[:,:])\n",
    "test_labels = np.column_stack((test_labels,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 12)\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(fit_intercept= False, normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_test.columns=ii.columns\n",
    "idf_test.index=ii.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vita_values = train_features.get([\"pid\",\"Heartrate\", \"SpO2\", \"ABPs\", \"ABPm\", \"ABPd\", \"RRate\", \"Temp\" ])\n",
    "display(Vita_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Vita_values[0:30]\n",
    "display(ss.std())\n",
    "tt = Vita_values.groupby('pid').mean()\n",
    "display(tt,tt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###result = pd.concat([X_test_pid,pd.DataFrame(__result here__)],axis=1)\n",
    "result = pd.concat([X_test_pid.drop_duplicates()],axis=1)\n",
    "\n",
    "pd.DataFrame(result).to_csv(\"submit.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
