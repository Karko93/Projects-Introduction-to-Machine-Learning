{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "\n",
    "### Train set data\n",
    "X_train_features = train_features.drop(columns=[\"pid\"])\n",
    "X_train_pid = train_features.get(\"pid\") ## just in case if needed\n",
    "y_train_labels = train_labels.drop(columns = [\"pid\"])\n",
    "train_label_pid = train_labels.get(\"pid\") ## just in case if needed\n",
    "\n",
    "### Test set data\n",
    "X_test_features = test_features.drop(columns = [\"pid\"])\n",
    "X_test_pid = test_features.get(\"pid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pids(feat_dataframe):\n",
    "    \n",
    "    \n",
    "    all_pids = feat_dataframe[\"pid\"].unique()\n",
    "    return all_pids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pid = extract_pids(train_features)\n",
    "\n",
    "train_pid, val_pid = train_test_split(all_pid, train_size= 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(missing_values=np.NaN,n_nearest_features=4)\n",
    "mask = train_features['pid'].isin(train_pid)\n",
    "oo = train_features.loc[mask]#.drop(columns = [\"pid\"])\n",
    "idf=pd.DataFrame(imputer.fit_transform(oo))\n",
    "idf.columns=oo.columns\n",
    "idf.index=oo.index\n",
    "mask_kk = train_labels['pid'].isin(train_pid)\n",
    "kk = train_labels.loc[mask_kk]\n",
    "\n",
    "\n",
    "mask2 = train_labels['pid'].isin(val_pid)\n",
    "val_labels = train_labels.loc[mask2].drop(columns = [\"pid\"]).to_numpy()\n",
    "val_features = train_features['pid'].isin(val_pid).drop(columns = [\"pid\"])\n",
    "\n",
    "mask3 = train_features['pid'].isin(val_pid)\n",
    "pp = train_features.loc[mask3]#.drop(columns = [\"pid\"])\n",
    "idf_val=pd.DataFrame(imputer.fit_transform(pp))\n",
    "idf_val.columns=pp.columns\n",
    "idf_val.index=pp.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2', 'LABEL_Sepsis', 'LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate'] [    1    10   100  1000 10000 10002 10006 10007 10009  1001] [ 1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000. 10000. 10000.]\n",
      "(15196,)\n"
     ]
    }
   ],
   "source": [
    "print(list(kk), kk['pid'].to_numpy()[0:10], idf['pid'].to_numpy()[40:50])\n",
    "#print(kk[['pid','LABEL_Sepsis']])\n",
    "print(train_pid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(dataframe):\n",
    "    for (columnName, columnData) in dataframe.iteritems():\n",
    "        numb_rows = columnData.shape\n",
    "        not_NaN = columnData.count()\n",
    "        if not_NaN==0: continue\n",
    "        elif not_NaN == 1:\n",
    "            dataframe[columnName] = columnData.fillna(columnData.mean())\n",
    "        else:\n",
    "            dataframe[columnName] = columnData.interpolate()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(patient_data):\n",
    "    relevant_data = patient_data\n",
    "    #relevant_data = patient_data.drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    feat1 = relevant_data.mean().to_numpy().reshape(1,-1)\n",
    "    feat2 = relevant_data.std().to_numpy().reshape(1,-1)\n",
    "    feat3 = relevant_data.max().to_numpy().reshape(1,-1)\n",
    "    patient_features = np.hstack((feat1,feat2))\n",
    "    return patient_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features(idf[idf['pid'] == train_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))\n",
    "labels = train_labels[train_labels['pid'] == train_pid[0]].drop(columns=[\"pid\"]).to_numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   25.6\n",
      "   73.7  97.2 105.3]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15196, 68) (1, 15) (15196, 15)\n"
     ]
    }
   ],
   "source": [
    "for pid in train_pid[1:]:\n",
    "    X_pid = idf[idf['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    features = np.vstack((features,X_feat))\n",
    "    y_pid = train_labels[train_labels['pid'] == pid].drop(columns=[\"pid\"])\n",
    "    labels= np.vstack((labels,y_pid))\n",
    "    \n",
    "print(features.shape, y_pid.shape, labels.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = create_features(idf_val[idf_val['pid'] == val_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))\n",
    "val_labels = train_labels[train_labels['pid'] == val_pid[0]].drop(columns=[\"pid\"]).to_numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3799, 68) (1, 15) (3799, 15)\n"
     ]
    }
   ],
   "source": [
    "for pid in val_pid[1:]:\n",
    "    X_pid = idf_val[idf_val['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    val_features = np.vstack((val_features,X_feat))\n",
    "    y_pid = train_labels[train_labels['pid'] == pid].drop(columns=[\"pid\"])\n",
    "    val_labels= np.vstack((val_labels,y_pid))\n",
    "    \n",
    "print(val_features.shape, y_pid.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels[0,1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = svm.SVC(kernel='sigmoid', probability= True)\n",
    "clf.fit(features, labels[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict_proba(val_features[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "test_pid = extract_pids(test_features)\n",
    "mask_test = test_features['pid'].isin(test_pid)\n",
    "ii = test_features.loc[mask_test]#.drop(columns = [\"pid\"])\n",
    "idf_test=pd.DataFrame(imputer.fit_transform(ii))\n",
    "idf_test.columns=ii.columns\n",
    "idf_test.index=ii.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_features = create_features(idf_test[idf_test['pid'] == test_pid[0]].drop(columns=[\"Time\",\"Age\",\"pid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 68)\n"
     ]
    }
   ],
   "source": [
    "for pid in test_pid[1:]:\n",
    "    X_pid = idf_test[idf_test['pid'] == pid].drop(columns=[\"Time\",\"Age\",\"pid\"])\n",
    "    #X_pid = features[features[:,0]==pid,:]\n",
    "    #X_pid = impute_missing_data(X_pid)\n",
    "    X_feat = create_features(X_pid)\n",
    "    t_features = np.vstack((t_features,X_feat))\n",
    "\n",
    "    \n",
    "print(t_features.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz =kk[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']]\n",
    "print(tz.to_numpy().shape)\n",
    "## ['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2', 'LABEL_Sepsis', 'LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_pid\n",
    "model = MLPClassifier(activation='logistic')\n",
    "model.fit(features, labels[:,0:10])\n",
    "#model.fit(features, kk[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']].to_numpy()) ####\n",
    "y_hat = model.predict_proba(t_features[:,:])\n",
    "test_labels = np.column_stack((test_labels,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[0:10,1])\n",
    "ss = kk['LABEL_Sepsis'].to_numpy()\n",
    "print(ss.shape, features.shape)\n",
    "print(ss[ss==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', probability= False)\n",
    "#clf.fit(features, labels[:,10] ) kk['pid'].to_numpy()\n",
    "clf.fit(features, ss )\n",
    "y_hat = clf.predict(t_features[:,:])\n",
    "test_labels = np.column_stack((test_labels,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression(fit_intercept= False, normalize= False)\n",
    "y_hat = reg.fit(features, labels[:,11:]).predict(t_features[:,:])\n",
    "test_labels = np.column_stack((test_labels,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 16) (18995, 16)\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.shape, train_labels.to_numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.DataFrame(test_labels)\n",
    "test_labels.columns=train_labels.columns\n",
    "results = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###result = pd.concat([X_test_pid,pd.DataFrame(__result here__)],axis=1)\n",
    "result = pd.concat([X_test_pid.drop_duplicates()],axis=1)\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"submit_Ketzel.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vita_values = train_features.get([\"pid\",\"Heartrate\", \"SpO2\", \"ABPs\", \"ABPm\", \"ABPd\", \"RRate\", \"Temp\" ])\n",
    "display(Vita_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Vita_values[0:30]\n",
    "display(ss.std())\n",
    "tt = Vita_values.groupby('pid').mean()\n",
    "display(tt,tt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
